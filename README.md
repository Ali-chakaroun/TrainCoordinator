# Train Coordinator ðŸš† (Prototype)

This is a **prototype Train Coordinator service** designed for orchestrating workflows and enforcing access control in **privacy-preserving data analysis** for federated healthcare environments.  

This project extends the **FAIR Data Train (FDT)** framework by integrating:  
- [**Common Workflow Language (CWL)**](https://www.commonwl.org/user_guide/introduction/quick-start.html) for multi-step workflow execution.  
- [**Open Digital Rights Language (ODRL)**](https://www.w3.org/TR/odrl-model/) for fine-grained data access control.  

---

## ðŸ“Œ Features

- **Automated multi-step analysis** â€” chain multiple trains with conditional execution.  
- **Policy-based access control** â€” enforce data retrieval policies usage with ODRL.  
- **Reusable workflows** â€” built using CWL for portability and reproducibility.



| Endpoint                                          | Method | Description                                                                                                                                                         |
| ------------------------------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `http://localhost:6060/api/analysis/execute`      | `POST` | Executes a CWL workflow and returns the result.                                                                                                                     |
| `http://localhost:6060/api/analysis/odrl-execute` | `POST` | Executes an ODRL policy request and returns the corresponding SPARQL query. *(Note: CWL workflows internally call this endpoint when verifying train permissions.)* |

### `/api/analysis/odrl-execute` Payload Format

This endpoint expects the request body in **raw** format, describing an ODRL request.  
Example payload:

```turtle
@prefix odrl:   <http://www.w3.org/ns/odrl/2/> .
@prefix ex:     <http://example.org/> .

<http://example.org/request:se-query>
    a odrl:Request ;
    odrl:uid <https://www.wikidata.org/wiki/Q25670> ;
    odrl:profile <https://www.wikidata.org/wiki/Q4382010> ;

    odrl:permission [
        odrl:target <http://example.org/graph/extract_data> ;
        odrl:assignee ex:researcher ;
        odrl:action odrl:read
    ] .

```
---

## ðŸ“‚ File Paths

The prototype stores its **workflows** and **local RDF-based data stations** in: **src/main/resources/workflow**

This folder contains:  
- **CWL Workflow files** â€” define the steps, inputs, and conditional execution logic for the analysis.  
- **RDF files** â€” serve as *local data stations* from which the workflow extracts data using SPARQL queries.  

### **ODRL Engine**
The **ODRL engine configuration and policies** used for access control are located in: **src/main/resources/ODRL**

This folder contains:
- **Policies** â€” define permissions, prohibitions, and obligations for data access.  
- **Engine** â€” policy engine that validates access requests against internal policies and if allowed, returns the corresponding SPARQL query file to execute.
- **Data** - holds a sparql query for the requested data when the an data access request is accepted.

### Output Directory
The `output` folder stores the resulting data generated by the workflow execution.

## ui Directory
The `ui/` folder contains a **Streamlit-based interface** for visualizing the data produced in the `output/` folder as a chart.  
Make sure you have Python 3.9+ installed, then install the required libraries:
```bash
pip install streamlit streamlit-agraph rdflib pandas networkx matplotlib
```
After installation of the required libraries you can use the command below to run the script.
```bash
streamlit run ui/sideEffect_chart.py
```
**Note:** 
On some Windows setups, running `streamlit run` directly may fail with an error.
If that happens, try the following alternative command:

```bash
python -m streamlit run ui/sideEffect_chart.py
```

## ðŸ§© Installation & Setup (Prototype)

âš  **Note:**  
This prototype **only runs on Linux** based OS (Debian/Ubuntu)
---

### 1) Prerequisites
- **Java JDK**: 17+
- **Maven**: 3.6+
- **Python**: 3.9+
- **Docker**: latest

### 2) Clone the repository
```bash
git clone to/do
cd TrainCoordinator
```
### 3) Dockerize python scripts
```bash
cd scripts
# build each image
docker build -t extract-adr .           
docker build -t extract-lareb-data .    
docker build -t extract-vigi-data .     
docker build -t extract-sideeff-data . 
```
### 4) install 'cwltool'
```bash
python3 -m pip install --upgrade pip
pip install cwltool
```
### 5) Run the service
```bash
mvn clean package
mvn spring-boot:run
```
